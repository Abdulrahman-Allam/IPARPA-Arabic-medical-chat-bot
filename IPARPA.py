import streamlit as st
import sys
import google.generativeai as genai

# Ensure UTF-8 encoding
sys.stdout.reconfigure(encoding='utf-8')

# Configure Gemini client
def initialize_gemini_client():
    genai.configure(api_key="AIzaSyCrfSGQ4rzgkb-698AI69k8NFb4-gTguiA")
    return genai.GenerativeModel("gemini-1.5-flash")

# Function to generate response from Gemini API
def generate_response(messages, model):
    try:
        # Combine messages into a single prompt (e.g., a conversation)
        prompt = "\n".join([
            f"{message['role']}: {message['content']}"
            for message in messages
        ])
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

# Streamlit app setup
st.set_page_config(
    page_title="IPARPA - Ù…Ø³Ø§Ø¹Ø¯ Ø·Ø¨ÙŠ",
    page_icon="ğŸ©º",
    layout="wide",
    initial_sidebar_state="expanded"
)

# st.sidebar.image("https://via.placeholder.com/150", use_column_width=True)
st.sidebar.markdown(
    """<h2 style='color: #2E86C1;'>!IPARPAÙ…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ùƒ ÙÙŠ </h2>
    <p style='color: white;'>
    Ù†Ø­Ù† Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªÙØ³Ø§Ø±Ø§ØªÙƒ Ø§Ù„Ø·Ø¨ÙŠØ©.
    Ø§Ø³ØªØ®Ø¯Ù… ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø£Ø¯Ù†Ø§Ù‡ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©.
    </p>""",
    unsafe_allow_html=True
)

st.markdown("""<style>.css-18e3th9 {padding: 1rem;}</style>""", unsafe_allow_html=True)

st.markdown("<h1 style='text-align:center; color: #2E86C1;'>IPARPA - Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ</h1>", unsafe_allow_html=True)

# Initialize chat session
if 'messages' not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "Ø§Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø·Ø¨ÙŠ Ù…ØµØ±ÙŠ Ø°ÙƒÙŠ, Ù…Ø¨ØªØªÙƒÙ„Ù…Ø´ ØºÙŠØ± Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©, Ø¨ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù†Ø§Ø³ ÙÙŠ Ø§Ù†Ùƒ ØªØ¬Ø§ÙˆØ¨Ù‡Ù… Ø¹Ù„Ù‰ Ø§Ø³Ø£Ù„ØªÙ‡Ù… Ø§Ù„Ø·Ø¨ÙŠØ©, ÙˆØ¯Ø§ÙŠÙ…Ø§ Ù„Ù…Ø§ ÙŠÙ‚ÙˆÙ„ÙˆÙ„Ùƒ Ø´ÙƒÙˆØªÙ‡Ù… ØªÙ‚ÙˆÙ„Ù‡Ù… Ø§Ù„Ù Ø³Ù„Ø§Ù…Ø© Ø§Ùˆ Ø³Ù„Ø§Ù…ØªÙƒ ÙˆØ¨Ø¹Ø¯ÙŠÙ† ØªØ±Ø¯ Ø¹Ù„ÙŠÙ‡Ù… Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø±Ø³Ù…ÙŠØ©, ÙˆÙƒÙ…Ø§Ù† ØªÙ‚ÙˆÙ„Ù‡Ù… Ø§ÙŠÙ‡ Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø§Ù„Ù„ÙŠ Ø§Ù„ÙÙ…Ø±ÙˆØ¶ ÙŠØ¹Ù…Ù„ÙˆÙ‡Ø§, ÙˆÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ø¬Ø§Ø¨ØªÙƒ Ø¯Ø§ÙŠÙ…Ø§ Ø§Ø³Ø§Ù„Ù‡Ù… Ù‡Ù„ ØªØ­Ø¨ Ø§Ø­Ø¬Ø²Ù„Ùƒ Ù„Ø¯ÙƒØªÙˆØ±, Ø§ÙŠ Ø³Ø¤Ø§Ù„ Ù…Ù„ÙˆØ´ Ø¹Ù„Ø§Ù‚Ø© Ø¨Ø§Ù„Ø·Ø¨ Ø§Ø¹ØªØ°Ø± Ù…Ù†Ù‡ ÙˆÙ…ØªØ¬Ø§ÙˆØ¨Ø´, Ù…Ù…ÙƒÙ† ØªØ±Ø¯ Ø§Ù„Ø³Ù„Ø§Ù… Ø§Ùˆ Ø§Ù„ØªØ±Ø­Ø§Ø¨ Ù…ÙÙŠØ´ Ù…Ø´Ø§ÙƒÙ„, ÙƒÙ„ Ø§Ø¬ÙˆØ¨ØªÙƒ Ù‚ÙˆÙ„Ù‡Ø§ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø±Ø³Ù…ÙŠØ© ÙˆØ¨Ø£Ø¯Ø¨"}    ]

# Display previous messages
for message in st.session_state.messages:
    if message['role'] == 'user':
        st.chat_message('user').markdown(message['content'])
    elif message['role'] == 'assistant':
        st.chat_message('assistant').markdown(message['content'])

# Initialize the Gemini client once
if 'gemini_model' not in st.session_state:
    st.session_state.gemini_model = initialize_gemini_client()

# User input
prompt = st.chat_input("...Ø§ØªÙØ¶Ù„ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ")

if prompt:
    st.chat_message('user').markdown(prompt)
    st.session_state.messages.append({'role': 'user', 'content': prompt})
    # Check for specific command and redirect
    if prompt.strip() == "Ø§Ù‡ Ø§Ø­Ø¬Ø²Ù„ÙŠ":
        st.chat_message('assistant').markdown("...Ù‡ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„Ùƒ Ù„ØµÙØ­Ø© Ø§Ù„Ø­Ø¬Ø² [Ø§Ø¶ØºØ· Ù‡Ù†Ø§](./%D8%A7%D8%AD%D8%AC%D8%B2)")
    else:
        # Generate and display response
        with st.spinner("...ØªØ­Ù„ÙŠÙ„"):
            response = generate_response(st.session_state.messages, st.session_state.gemini_model)
            st.chat_message('assistant').markdown(response)
            st.session_state.messages.append({'role': 'assistant', 'content': response})
